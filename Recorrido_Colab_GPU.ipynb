{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recorrido Colab GPU.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyONdyewqBgn2l7oqnylnI24",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Afes4/Recorrido-Colab-CPU/blob/main/Recorrido_Colab_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiH8HgecAGha",
        "outputId": "1a0adb1f-91a4-4e93-9f06-4d603e54a690"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib-venn in /usr/local/lib/python3.7/dist-packages (0.11.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from matplotlib-venn) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from matplotlib-venn) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from matplotlib-venn) (1.21.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->matplotlib-venn) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->matplotlib-venn) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->matplotlib-venn) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->matplotlib-venn) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->matplotlib-venn) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install matplotlib-venn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get -qq install -y libfluidsynth1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbqVbQnwB2Py",
        "outputId": "7e3f7e32-c6f0-408d-d3f2-00a1f6390bd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package libfluidsynth1:amd64.\n",
            "(Reading database ... 155335 files and directories currently installed.)\n",
            "Preparing to unpack .../libfluidsynth1_1.1.9-1_amd64.deb ...\n",
            "Unpacking libfluidsynth1:amd64 (1.1.9-1) ...\n",
            "Setting up libfluidsynth1:amd64 (1.1.9-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pypi.python.org/pypi/libarchive\n",
        "!apt-get -qq install -y libarchive-dev && pip install -U libarchive\n",
        "import libarchive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alAzsoG4B6fE",
        "outputId": "cd06161c-e1e5-4abe-dfa1-cbe31f288b29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 155340 files and directories currently installed.)\n",
            "Preparing to unpack .../libarchive-dev_3.2.2-3.1ubuntu0.7_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.2.2-3.1ubuntu0.7) ...\n",
            "Setting up libarchive-dev:amd64 (3.2.2-3.1ubuntu0.7) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting libarchive\n",
            "  Downloading libarchive-0.4.7.tar.gz (23 kB)\n",
            "Collecting nose\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[K     |████████████████████████████████| 154 kB 28.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: libarchive\n",
            "  Building wheel for libarchive (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libarchive: filename=libarchive-0.4.7-py3-none-any.whl size=31646 sha256=06d1cc5cba856a9bdb68d119d32840412a08310495b9d458d7ebda352a3e60bc\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/b1/c6/b3da79bec2012175bd43603eed98ef8548ac1733b77c1d4330\n",
            "Successfully built libarchive\n",
            "Installing collected packages: nose, libarchive\n",
            "Successfully installed libarchive-0.4.7 nose-1.3.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pypi.python.org/pypi/pydot\n",
        "!apt-get -qq install -y graphviz && pip install pydot\n",
        "import pydot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9w-RmoZCAKC",
        "outputId": "9e7eb1ec-ca79-4a63-de4a-a2f281cff2f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.7/dist-packages (from pydot) (3.0.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cartopy\n",
        "import cartopy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFuVHnjyCDZS",
        "outputId": "d45a6ece-ce58-4e23-ae95-c26cc7e716e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cartopy\n",
            "  Downloading Cartopy-0.20.2.tar.gz (10.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.8 MB 22.2 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/f6/55/1e1c737dc9436b320deead73d1c455ddbb74b8b6992081863492f6f6378a/Cartopy-0.20.2.tar.gz#sha256=4d08c198ecaa50a6a6b109d0f14c070e813defc046a83ac5d7ab494f85599e35 (from https://pypi.org/simple/cartopy/) (requires-python:>=3.7). Command errored out with exit status 1: /usr/bin/python3 /usr/local/lib/python3.7/dist-packages/pip/_vendor/pep517/in_process/_in_process.py get_requires_for_build_wheel /tmp/tmpgk28o0db Check the logs for full command output.\u001b[0m\n",
            "  Downloading Cartopy-0.20.1.tar.gz (10.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.8 MB 41.1 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/fc/59/aa52698e3838f4cd0e7eaa75bd86837e9e0b05041dbdaee3cda2fffced06/Cartopy-0.20.1.tar.gz#sha256=91f87b130e2574547a20cd634498df97d797abd12dcfd0235bc0cdbcec8b05e3 (from https://pypi.org/simple/cartopy/) (requires-python:>=3.7). Command errored out with exit status 1: /usr/bin/python3 /usr/local/lib/python3.7/dist-packages/pip/_vendor/pep517/in_process/_in_process.py get_requires_for_build_wheel /tmp/tmpirhx9_oj Check the logs for full command output.\u001b[0m\n",
            "  Downloading Cartopy-0.20.0.tar.gz (10.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.8 MB 47.9 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/0f/c0/58453b036e79046d211f083880d58dcce787e7e07647ac25dc46c6555099/Cartopy-0.20.0.tar.gz#sha256=eae58aff26806e63cf115b2bce9477cedc4aa9f578c5e477b2c25cfa404f2b7a (from https://pypi.org/simple/cartopy/) (requires-python:>=3.7). Command errored out with exit status 1: /usr/bin/python3 /usr/local/lib/python3.7/dist-packages/pip/_vendor/pep517/in_process/_in_process.py get_requires_for_build_wheel /tmp/tmpnfwb29tm Check the logs for full command output.\u001b[0m\n",
            "  Downloading Cartopy-0.19.0.post1.tar.gz (12.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.1 MB 52.8 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: shapely>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from cartopy) (1.8.1.post1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from cartopy) (1.21.5)\n",
            "Collecting pyshp>=2\n",
            "  Downloading pyshp-2.2.0-py3-none-any.whl (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 3.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: cartopy\n",
            "  Building wheel for cartopy (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cartopy: filename=Cartopy-0.19.0.post1-cp37-cp37m-linux_x86_64.whl size=12516284 sha256=136960a9dcd1b876f2878adb8710b2726d0db4d7ad688e6fa2258b5a636a48d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/01/f7/bd10aeb96fe4b518cde5f7c4f5e12c7202f85b7353a5017847\n",
            "Successfully built cartopy\n",
            "Installing collected packages: pyshp, cartopy\n",
            "Successfully installed cartopy-0.19.0.post1 pyshp-2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lectura de datos"
      ],
      "metadata": {
        "id": "IeOXCKgKCYg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Lectura del set de datos"
      ],
      "metadata": {
        "id": "OeF76lzmCbTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import gzip\n",
        "\n",
        "def cargar_set(ruta, tipo='train'):\n",
        "\n",
        "\n",
        "    ruta_categorias = os.path.join(ruta, '%s-labels-idx1-ubyte.gz' % tipo)\n",
        "    ruta_imagenes = os.path.join(ruta, '%s-images-idx3-ubyte.gz' % tipo)\n",
        "    \n",
        "    with gzip.open(ruta_categorias, 'rb') as rut_cat:\n",
        "        etiquetas = np.frombuffer(rut_cat.read(), dtype=np.uint8, offset=8)\n",
        "\n",
        "    with gzip.open(ruta_imagenes, 'rb') as rut_imgs:\n",
        "        imagenes = np.frombuffer(rut_imgs.read(), dtype=np.uint8, offset=16).reshape(len(etiquetas), 784)\n",
        "\n",
        "    return imagenes, etiquetas \n"
      ],
      "metadata": {
        "id": "GKLmEjemCgsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Acceso a Google Drive"
      ],
      "metadata": {
        "id": "sg5oKqAZCmYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "ruta = 'gdrive/MyDrive/Colab Notebooks/fashion_mnist_data'\n",
        "\n",
        "X_train, Y_train = cargar_set(ruta, tipo='train')\n",
        "X_test, Y_test = cargar_set(ruta, tipo='t10k')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeV1tan5IXDw",
        "outputId": "b50256e1-4c4b-4a0e-83dc-61bc27c080ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reajustar el tamaño de los datos"
      ],
      "metadata": {
        "id": "AvObjyGNP4US"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train[0:59904,:]\n",
        "X_test = X_test[0:9984,:]\n",
        "Y_train = Y_train[0:59904]\n",
        "Y_test = Y_test[0:9984]\n",
        "\n",
        "X_train = np.reshape(X_train,(59904,28,28,1))\n",
        "X_test = np.reshape(X_test,(9984,28,28,1))"
      ],
      "metadata": {
        "id": "3EqXHWS-QwDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x   \n",
        "import tensorflow as tf\n",
        "print('Versión de TensorFlow: ' + tf.__version__)\n",
        "\n",
        "tf.random.set_seed(200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wl6Q_2rVRLBu",
        "outputId": "ba523786-192c-4669-fe2e-ea6314f0b67d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Versión de TensorFlow: 2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Creación del modelo"
      ],
      "metadata": {
        "id": "XDlCWKpyR1se"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n",
        "model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='elu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n",
        "model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n",
        "model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256))\n",
        "model.add(tf.keras.layers.Activation('elu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10))\n",
        "model.add(tf.keras.layers.Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBSOv75nR2k4",
        "outputId": "cae1000b-8e78-4f42-ee0b-f06827975761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization_3 (Batc  (None, 28, 28, 1)        4         \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 28, 28, 64)        1664      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 14, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 14, 14, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 14, 14, 128)       204928    \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 7, 7, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 7, 7, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 7, 7, 256)         819456    \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 3, 3, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 3, 3, 256)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2304)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               590080    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,619,470\n",
            "Trainable params: 1,619,084\n",
            "Non-trainable params: 386\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento con CPU"
      ],
      "metadata": {
        "id": "sawxm1LkSkKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "NFjYyIXoSn1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "\n",
        "def entrenamiento_cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    model.fit(X_train,Y_train,validation_data=(X_test,Y_test),batch_size=128,epochs=2,verbose=1)\n",
        "  \n",
        "  return None\n",
        "\n",
        "cpu_time = timeit.timeit('entrenamiento_cpu()', number=1, setup='from __main__ import entrenamiento_cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzlTQudaTDLa",
        "outputId": "1b577845-ff14-4025-da93-ae199b8ca196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "468/468 [==============================] - 669s 1s/step - loss: 0.7192 - accuracy: 0.7740 - val_loss: 0.3790 - val_accuracy: 0.8654\n",
            "Epoch 2/2\n",
            "468/468 [==============================] - 668s 1s/step - loss: 0.4009 - accuracy: 0.8598 - val_loss: 0.3140 - val_accuracy: 0.8918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Tiempo de entrenamiento' + str(cpu_time) + 'segundos')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQa5sWeSYftg",
        "outputId": "9aece1bb-c15a-4af6-84e9-2be84d400a15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de entrenamiento1343.0501568400005segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Verificar la disponibilidad de la GPU"
      ],
      "metadata": {
        "id": "PC-Xl7wKpfvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "nombre_gpu = tf.test.gpu_device_name()\n",
        "if nombre_gpu != \"/device:GPU:0\":\n",
        "  raise SystemError(\"GPU no encontrada\")\n",
        "print(\"GPU encontrada: {}\".format(nombre_gpu))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqOJW60cpgvS",
        "outputId": "84144f9f-2f06-4844-d0fb-f7b24987ff0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU encontrada: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento con GPU"
      ],
      "metadata": {
        "id": "bzyVZNd9q7PF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n",
        "model.add(tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='elu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n",
        "model.add(tf.keras.layers.Conv2D(128, (5, 5), padding='same', activation='elu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=X_train.shape[1:]))\n",
        "model.add(tf.keras.layers.Conv2D(256, (5, 5), padding='same', activation='elu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
        "model.add(tf.keras.layers.Dropout(0.25))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256))\n",
        "model.add(tf.keras.layers.Activation('elu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10))\n",
        "model.add(tf.keras.layers.Activation('softmax'))"
      ],
      "metadata": {
        "id": "O-krutLvq9Lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timeit\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
        "    # Loss function to minimize\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "    # List of metrics to monitor\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "def entrenamiento_gpu():\n",
        "  with tf.device(\"/device:GPU:0\"):\n",
        "    model.fit(X_train,Y_train,validation_data=(X_test,Y_test),batch_size=64,epochs=2,verbose=1)\n",
        "  \n",
        "  return None\n",
        "\n",
        "gpu_time = timeit.timeit(\"entrenamiento_gpu()\", number=1, setup=\"from __main__ import entrenamiento_gpu\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-na5w1zr6ta",
        "outputId": "f16a8b84-07a1-43d1-8b66-560ce3cff553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "936/936 [==============================] - 21s 11ms/step - loss: 0.8264 - sparse_categorical_accuracy: 0.7753 - val_loss: 0.4898 - val_sparse_categorical_accuracy: 0.8482\n",
            "Epoch 2/2\n",
            "936/936 [==============================] - 10s 11ms/step - loss: 0.4307 - sparse_categorical_accuracy: 0.8549 - val_loss: 0.3629 - val_sparse_categorical_accuracy: 0.8754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tiempo de entrenamiento\" + str(gpu_time) + \"segundos\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heaIe8JluKFd",
        "outputId": "2dc73903-d70c-4e82-f952-07510013e824"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de entrenamiento42.06899881000004segundos\n"
          ]
        }
      ]
    }
  ]
}